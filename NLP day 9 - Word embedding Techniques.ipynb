{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python_version>\"3.7\" in c:\\users\\lmbmo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-gpu) (0.0.2)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py): started\n",
      "  Building wheel for tensorflow-gpu (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n",
      "Installing collected packages: tensorflow-gpu\n",
      "  Running setup.py install for tensorflow-gpu: started\n",
      "  Running setup.py install for tensorflow-gpu: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [18 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\lmbmo\\AppData\\Local\\Temp\\pip-install-od84r0v3\\tensorflow-gpu_e46afad5e6244004960799992c11f8c8\\setup.py\", line 37, in <module>\n",
      "          raise Exception(TF_REMOVAL_WARNING)\n",
      "      Exception:\n",
      "      \n",
      "      =========================================================\n",
      "      The \"tensorflow-gpu\" package has been removed!\n",
      "      \n",
      "      Please install \"tensorflow\" instead.\n",
      "      \n",
      "      Other than the name, the two packages have been identical\n",
      "      since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "      information, see: pypi.org/project/tensorflow-gpu\n",
      "      =========================================================\n",
      "      \n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tensorflow-gpu\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for tensorflow-gpu did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [18 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\lmbmo\\AppData\\Local\\Temp\\pip-install-od84r0v3\\tensorflow-gpu_e46afad5e6244004960799992c11f8c8\\setup.py\", line 37, in <module>\n",
      "          raise Exception(TF_REMOVAL_WARNING)\n",
      "      Exception:\n",
      "      \n",
      "      =========================================================\n",
      "      The \"tensorflow-gpu\" package has been removed!\n",
      "      \n",
      "      Please install \"tensorflow\" instead.\n",
      "      \n",
      "      Other than the name, the two packages have been identical\n",
      "      since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "      information, see: pypi.org/project/tensorflow-gpu\n",
      "      =========================================================\n",
      "      \n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> tensorflow-gpu\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "##tensorflow >2.0\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'the glass of juice',\n",
       " 'the cup of tea',\n",
       " 'I am a good boy',\n",
       " 'I am a good developer',\n",
       " 'understand the meaning of words',\n",
       " 'your videos are good']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### sentences\n",
    "sent=[  'the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "     'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good']\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "voc_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82, 96, 290, 175], [82, 96, 290, 10], [82, 138, 290, 226], [494, 114, 238, 305, 419], [494, 114, 238, 305, 370], [457, 82, 64, 290, 249], [18, 270, 450, 305]]\n"
     ]
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,voc_size)for words in sent] \n",
    "print(onehot_repr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length is 5\n"
     ]
    }
   ],
   "source": [
    "sent_length = 0\n",
    "for i in range(len(sent)):\n",
    "    if len(sent[i].split()) > sent_length:\n",
    "        sent_length = len(sent[i].split())\n",
    "print(f'Maximum sentence length is {sent_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0  82  96 290 175]\n",
      " [  0   0   0   0  82  96 290  10]\n",
      " [  0   0   0   0  82 138 290 226]\n",
      " [  0   0   0 494 114 238 305 419]\n",
      " [  0   0   0 494 114 238 305 370]\n",
      " [  0   0   0 457  82  64 290 249]\n",
      " [  0   0   0   0  18 270 450 305]]\n"
     ]
    }
   ],
   "source": [
    "#pre padding\n",
    "sent_length=sent_length+3\n",
    "# we increase the setn_length a little to not have out of vocab issue\n",
    "embedded_docs=pad_sequences(onehot_repr, padding='pre', maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature representation\n",
    "dim=10\n",
    "# 10 should be enough as we very small sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             5000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,000\n",
      "Trainable params: 5,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size, dim, input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,  82,  96, 290, 175])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,  0.00224423,\n",
       "        -0.01572689, -0.00613006, -0.02783823,  0.02065761,  0.02721696],\n",
       "       [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,  0.00224423,\n",
       "        -0.01572689, -0.00613006, -0.02783823,  0.02065761,  0.02721696],\n",
       "       [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,  0.00224423,\n",
       "        -0.01572689, -0.00613006, -0.02783823,  0.02065761,  0.02721696],\n",
       "       [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,  0.00224423,\n",
       "        -0.01572689, -0.00613006, -0.02783823,  0.02065761,  0.02721696],\n",
       "       [ 0.01124078,  0.01102644, -0.00688881,  0.01070916, -0.00382366,\n",
       "        -0.01973114,  0.0359012 , -0.01637311, -0.03529534,  0.03832814],\n",
       "       [ 0.010799  , -0.0460222 ,  0.01765305, -0.03532173,  0.02056715,\n",
       "        -0.03962339,  0.01036368,  0.00660773,  0.01819089,  0.022079  ],\n",
       "       [-0.03294869,  0.03080585, -0.03379887, -0.04127785, -0.00591446,\n",
       "        -0.01255221,  0.04429166, -0.00319735, -0.02003815,  0.01013631],\n",
       "       [-0.02083364, -0.03463663, -0.03529806,  0.0039156 ,  0.00616959,\n",
       "        -0.02835057, -0.02232246, -0.01852059,  0.04636345, -0.02667514]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [ 0.01124078,  0.01102644, -0.00688881,  0.01070916,\n",
       "         -0.00382366, -0.01973114,  0.0359012 , -0.01637311,\n",
       "         -0.03529534,  0.03832814],\n",
       "        [ 0.010799  , -0.0460222 ,  0.01765305, -0.03532173,\n",
       "          0.02056715, -0.03962339,  0.01036368,  0.00660773,\n",
       "          0.01819089,  0.022079  ],\n",
       "        [-0.03294869,  0.03080585, -0.03379887, -0.04127785,\n",
       "         -0.00591446, -0.01255221,  0.04429166, -0.00319735,\n",
       "         -0.02003815,  0.01013631],\n",
       "        [-0.02083364, -0.03463663, -0.03529806,  0.0039156 ,\n",
       "          0.00616959, -0.02835057, -0.02232246, -0.01852059,\n",
       "          0.04636345, -0.02667514]],\n",
       "\n",
       "       [[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [ 0.01124078,  0.01102644, -0.00688881,  0.01070916,\n",
       "         -0.00382366, -0.01973114,  0.0359012 , -0.01637311,\n",
       "         -0.03529534,  0.03832814],\n",
       "        [ 0.010799  , -0.0460222 ,  0.01765305, -0.03532173,\n",
       "          0.02056715, -0.03962339,  0.01036368,  0.00660773,\n",
       "          0.01819089,  0.022079  ],\n",
       "        [-0.03294869,  0.03080585, -0.03379887, -0.04127785,\n",
       "         -0.00591446, -0.01255221,  0.04429166, -0.00319735,\n",
       "         -0.02003815,  0.01013631],\n",
       "        [-0.00391871, -0.00595965,  0.00935002,  0.02005475,\n",
       "         -0.01675574,  0.02365998, -0.00525488, -0.02877443,\n",
       "          0.03976977, -0.0072868 ]],\n",
       "\n",
       "       [[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [ 0.01124078,  0.01102644, -0.00688881,  0.01070916,\n",
       "         -0.00382366, -0.01973114,  0.0359012 , -0.01637311,\n",
       "         -0.03529534,  0.03832814],\n",
       "        [-0.00520422, -0.01230333, -0.04966657, -0.01849326,\n",
       "         -0.02932147,  0.03003247, -0.03017145,  0.04209835,\n",
       "         -0.02708405, -0.04785359],\n",
       "        [-0.03294869,  0.03080585, -0.03379887, -0.04127785,\n",
       "         -0.00591446, -0.01255221,  0.04429166, -0.00319735,\n",
       "         -0.02003815,  0.01013631],\n",
       "        [ 0.02555338,  0.02364716,  0.02460071, -0.02814255,\n",
       "          0.00266795, -0.00214729, -0.00215634,  0.0411544 ,\n",
       "          0.00145163,  0.02659248]],\n",
       "\n",
       "       [[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [ 0.01350487,  0.01901766,  0.04628159, -0.02996603,\n",
       "          0.04085997, -0.04620261,  0.00853025, -0.01061512,\n",
       "          0.03228256,  0.02184008],\n",
       "        [-0.03851906,  0.02690536, -0.03483246,  0.00030131,\n",
       "          0.00434651, -0.0379668 ,  0.04230705, -0.01585182,\n",
       "         -0.04281938, -0.03555827],\n",
       "        [ 0.02149637,  0.04812998, -0.04067799, -0.00424648,\n",
       "          0.0032426 ,  0.02461794,  0.00015001,  0.01400652,\n",
       "          0.0076565 , -0.04556397],\n",
       "        [ 0.01307526, -0.04028672, -0.02824049,  0.01596883,\n",
       "          0.00444372, -0.04828272, -0.00298198, -0.04271434,\n",
       "          0.01369855, -0.04437684],\n",
       "        [-0.04170213, -0.02059519,  0.04164741,  0.00326539,\n",
       "         -0.00734498,  0.02014433, -0.02598996, -0.04828162,\n",
       "         -0.00586125,  0.02824153]],\n",
       "\n",
       "       [[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [ 0.01350487,  0.01901766,  0.04628159, -0.02996603,\n",
       "          0.04085997, -0.04620261,  0.00853025, -0.01061512,\n",
       "          0.03228256,  0.02184008],\n",
       "        [-0.03851906,  0.02690536, -0.03483246,  0.00030131,\n",
       "          0.00434651, -0.0379668 ,  0.04230705, -0.01585182,\n",
       "         -0.04281938, -0.03555827],\n",
       "        [ 0.02149637,  0.04812998, -0.04067799, -0.00424648,\n",
       "          0.0032426 ,  0.02461794,  0.00015001,  0.01400652,\n",
       "          0.0076565 , -0.04556397],\n",
       "        [ 0.01307526, -0.04028672, -0.02824049,  0.01596883,\n",
       "          0.00444372, -0.04828272, -0.00298198, -0.04271434,\n",
       "          0.01369855, -0.04437684],\n",
       "        [ 0.02344796, -0.04631395,  0.01955432, -0.00154495,\n",
       "          0.04829316, -0.01442761, -0.03025922, -0.01309418,\n",
       "         -0.04823206,  0.02536886]],\n",
       "\n",
       "       [[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.02354572,  0.01539259, -0.00591443,  0.04317934,\n",
       "         -0.0046797 ,  0.01379546, -0.023493  ,  0.01645224,\n",
       "         -0.03612776, -0.03971958],\n",
       "        [ 0.01124078,  0.01102644, -0.00688881,  0.01070916,\n",
       "         -0.00382366, -0.01973114,  0.0359012 , -0.01637311,\n",
       "         -0.03529534,  0.03832814],\n",
       "        [ 0.02505526, -0.0024217 ,  0.02623913,  0.01378408,\n",
       "         -0.04268823, -0.04273764,  0.00994173,  0.01351936,\n",
       "          0.0452901 ,  0.03810484],\n",
       "        [-0.03294869,  0.03080585, -0.03379887, -0.04127785,\n",
       "         -0.00591446, -0.01255221,  0.04429166, -0.00319735,\n",
       "         -0.02003815,  0.01013631],\n",
       "        [ 0.04872192, -0.00749625, -0.02075485,  0.02994302,\n",
       "         -0.02697041, -0.0394375 , -0.02045491,  0.04043642,\n",
       "         -0.03423967,  0.04203137]],\n",
       "\n",
       "       [[-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [-0.0270307 ,  0.00797524, -0.02988589,  0.00375221,\n",
       "          0.00224423, -0.01572689, -0.00613006, -0.02783823,\n",
       "          0.02065761,  0.02721696],\n",
       "        [ 0.0284606 , -0.0121304 ,  0.01712903, -0.04340959,\n",
       "          0.01514706, -0.04312878, -0.03908212, -0.00903662,\n",
       "          0.03351036, -0.00218274],\n",
       "        [-0.03611957, -0.03318731, -0.03860711,  0.01998485,\n",
       "          0.04507202, -0.00130811, -0.0155594 ,  0.0439038 ,\n",
       "         -0.03584014,  0.03904666],\n",
       "        [-0.01647056, -0.00262021,  0.03483878, -0.00988626,\n",
       "          0.03785329, -0.01307828, -0.0254065 , -0.02752641,\n",
       "          0.03282782,  0.00233001],\n",
       "        [ 0.01307526, -0.04028672, -0.02824049,  0.01596883,\n",
       "          0.00444372, -0.04828272, -0.00298198, -0.04271434,\n",
       "          0.01369855, -0.04437684]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assignment\n",
    "\n",
    "sent=[\"The world is a better place\",\n",
    "      \"Marvel movies are my favourite movie\",\n",
    "      \"I like DC movies\",\n",
    "      \"the cat is eating the food\",\n",
    "      \"Tom and Jerry is my favourite movie\",\n",
    "      \"Python is my favourite programming language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "voc_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82, 499, 384, 238, 415, 443], [49, 496, 450, 431, 423, 270], [494, 70, 345, 496], [82, 96, 384, 185, 82, 64], [91, 289, 493, 384, 431, 423, 270], [235, 384, 431, 423, 129, 427]]\n"
     ]
    }
   ],
   "source": [
    "onehot_repr=[one_hot(words,voc_size)for words in sent] \n",
    "print(onehot_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length is 7\n"
     ]
    }
   ],
   "source": [
    "sent_length = 0\n",
    "for i in range(len(sent)):\n",
    "    if len(sent[i].split()) > sent_length:\n",
    "        sent_length = len(sent[i].split())\n",
    "print(f'Maximum sentence length is {sent_length}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0  82 499 384 238 415 443]\n",
      " [  0   0   0   0  49 496 450 431 423 270]\n",
      " [  0   0   0   0   0   0 494  70 345 496]\n",
      " [  0   0   0   0  82  96 384 185  82  64]\n",
      " [  0   0   0  91 289 493 384 431 423 270]\n",
      " [  0   0   0   0 235 384 431 423 129 427]]\n"
     ]
    }
   ],
   "source": [
    "## pre padding\n",
    "sent_length=sent_length+3\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10 feature dimesnions\n",
    "dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 10, 10)            5000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,000\n",
      "Trainable params: 5,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,  82, 499, 384, 238, 415, 443])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##'The world is a better place',\n",
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 10) for input KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None,).\n",
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00953779,  0.03549981,  0.04574737,  0.00833737,  0.02803966,\n",
       "         0.03589184, -0.02499791,  0.04538051, -0.01218151,  0.04770775],\n",
       "       [ 0.00953779,  0.03549981,  0.04574737,  0.00833737,  0.02803966,\n",
       "         0.03589184, -0.02499791,  0.04538051, -0.01218151,  0.04770775],\n",
       "       [ 0.00953779,  0.03549981,  0.04574737,  0.00833737,  0.02803966,\n",
       "         0.03589184, -0.02499791,  0.04538051, -0.01218151,  0.04770775],\n",
       "       [ 0.00953779,  0.03549981,  0.04574737,  0.00833737,  0.02803966,\n",
       "         0.03589184, -0.02499791,  0.04538051, -0.01218151,  0.04770775],\n",
       "       [ 0.02681348, -0.03508812,  0.04007054, -0.00280043,  0.0015764 ,\n",
       "        -0.0448323 , -0.0357504 ,  0.03324788, -0.0113659 ,  0.02329982],\n",
       "       [ 0.02205027,  0.02083863,  0.03310417, -0.04064215,  0.017458  ,\n",
       "        -0.00155235, -0.03049693,  0.01933068,  0.04538289, -0.02658782],\n",
       "       [-0.0442851 ,  0.0098606 ,  0.02468357, -0.02099853, -0.03649157,\n",
       "         0.04909602,  0.04510445,  0.03730213, -0.04349843,  0.0327948 ],\n",
       "       [ 0.00245811, -0.03489213,  0.02522658, -0.03276129, -0.01239208,\n",
       "         0.01022691, -0.03478283,  0.04602673,  0.03943399, -0.04567561],\n",
       "       [ 0.04575119,  0.03466985, -0.03300028, -0.0329834 ,  0.00054464,\n",
       "        -0.01997802, -0.03733223,  0.02472936, -0.00129126, -0.04954653],\n",
       "       [-0.04081211, -0.03067806, -0.04331079,  0.0362413 ,  0.04480335,\n",
       "        -0.02757551,  0.03493085,  0.03147871, -0.00584577, -0.01709783]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "[[[ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.02681348 -0.03508812  0.04007054 -0.00280043  0.0015764\n",
      "   -0.0448323  -0.0357504   0.03324788 -0.0113659   0.02329982]\n",
      "  [ 0.02205027  0.02083863  0.03310417 -0.04064215  0.017458\n",
      "   -0.00155235 -0.03049693  0.01933068  0.04538289 -0.02658782]\n",
      "  [-0.0442851   0.0098606   0.02468357 -0.02099853 -0.03649157\n",
      "    0.04909602  0.04510445  0.03730213 -0.04349843  0.0327948 ]\n",
      "  [ 0.00245811 -0.03489213  0.02522658 -0.03276129 -0.01239208\n",
      "    0.01022691 -0.03478283  0.04602673  0.03943399 -0.04567561]\n",
      "  [ 0.04575119  0.03466985 -0.03300028 -0.0329834   0.00054464\n",
      "   -0.01997802 -0.03733223  0.02472936 -0.00129126 -0.04954653]\n",
      "  [-0.04081211 -0.03067806 -0.04331079  0.0362413   0.04480335\n",
      "   -0.02757551  0.03493085  0.03147871 -0.00584577 -0.01709783]]\n",
      "\n",
      " [[ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.02692023  0.03057105 -0.03533788 -0.00331464 -0.04179399\n",
      "   -0.02659981 -0.01046946  0.04757974  0.00538009 -0.04721419]\n",
      "  [-0.03094674 -0.02433147  0.00955447 -0.00915685  0.0102274\n",
      "   -0.01795841 -0.00932049  0.02422347  0.01590958 -0.00638049]\n",
      "  [ 0.04961513  0.04589968 -0.00193498  0.00802255  0.02887834\n",
      "    0.01836835 -0.0483654  -0.02843989  0.02039314  0.01625707]\n",
      "  [-0.00556684  0.02556572 -0.0135365  -0.01451286  0.03697691\n",
      "    0.0062049   0.04696387  0.03639454 -0.02742461 -0.04197062]\n",
      "  [ 0.03615865  0.03577119  0.00148784 -0.03431538 -0.04017918\n",
      "    0.00738523  0.03236402  0.01342156  0.0463609  -0.04213531]\n",
      "  [ 0.01897702  0.00507553 -0.03848269  0.00461119 -0.00999385\n",
      "   -0.04235666  0.0111828   0.00602607  0.04229739  0.03463305]]\n",
      "\n",
      " [[ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.03253021  0.04043921  0.03515358  0.03292209 -0.01962266\n",
      "   -0.01186667 -0.01609989 -0.03487357 -0.02422473  0.01126901]\n",
      "  [ 0.04899674  0.03111127  0.01431762  0.01712603 -0.04062576\n",
      "    0.01526949  0.02053572  0.0292895   0.02359804 -0.03003826]\n",
      "  [ 0.04281406 -0.00807271 -0.03545908  0.04641957  0.02295132\n",
      "    0.04374031  0.03303298 -0.02426529 -0.02099913 -0.04191235]\n",
      "  [-0.03094674 -0.02433147  0.00955447 -0.00915685  0.0102274\n",
      "   -0.01795841 -0.00932049  0.02422347  0.01590958 -0.00638049]]\n",
      "\n",
      " [[ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.02681348 -0.03508812  0.04007054 -0.00280043  0.0015764\n",
      "   -0.0448323  -0.0357504   0.03324788 -0.0113659   0.02329982]\n",
      "  [ 0.0167483   0.00011089  0.00864878 -0.04451151 -0.03529377\n",
      "    0.04667849  0.01928947 -0.01020049 -0.01114998 -0.00021119]\n",
      "  [-0.0442851   0.0098606   0.02468357 -0.02099853 -0.03649157\n",
      "    0.04909602  0.04510445  0.03730213 -0.04349843  0.0327948 ]\n",
      "  [ 0.02917923 -0.01050422 -0.02752188  0.01619128 -0.0141805\n",
      "   -0.03388821 -0.0111282  -0.04548743 -0.01042289  0.0102098 ]\n",
      "  [ 0.02681348 -0.03508812  0.04007054 -0.00280043  0.0015764\n",
      "   -0.0448323  -0.0357504   0.03324788 -0.0113659   0.02329982]\n",
      "  [ 0.04637532  0.04240359  0.03307815 -0.04196747  0.00239023\n",
      "    0.04786203 -0.04053271  0.00929447 -0.03793348  0.04908348]]\n",
      "\n",
      " [[ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [-0.038955    0.01935535  0.02834195 -0.01131564 -0.02357935\n",
      "    0.02189738 -0.00860218  0.02192593 -0.0041328   0.0064623 ]\n",
      "  [ 0.02455736 -0.01420329 -0.00046036  0.04051841 -0.01925927\n",
      "    0.00472556  0.0478824  -0.02740796 -0.00796677  0.03016039]\n",
      "  [ 0.04949186 -0.02202674  0.00398282 -0.03561167  0.00586154\n",
      "    0.02264616 -0.03443583  0.02617058  0.02252339  0.0292722 ]\n",
      "  [-0.0442851   0.0098606   0.02468357 -0.02099853 -0.03649157\n",
      "    0.04909602  0.04510445  0.03730213 -0.04349843  0.0327948 ]\n",
      "  [-0.00556684  0.02556572 -0.0135365  -0.01451286  0.03697691\n",
      "    0.0062049   0.04696387  0.03639454 -0.02742461 -0.04197062]\n",
      "  [ 0.03615865  0.03577119  0.00148784 -0.03431538 -0.04017918\n",
      "    0.00738523  0.03236402  0.01342156  0.0463609  -0.04213531]\n",
      "  [ 0.01897702  0.00507553 -0.03848269  0.00461119 -0.00999385\n",
      "   -0.04235666  0.0111828   0.00602607  0.04229739  0.03463305]]\n",
      "\n",
      " [[ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.00953779  0.03549981  0.04574737  0.00833737  0.02803966\n",
      "    0.03589184 -0.02499791  0.04538051 -0.01218151  0.04770775]\n",
      "  [ 0.02372361  0.02106235 -0.02535744  0.01366911  0.00954052\n",
      "    0.01218966  0.03414985  0.02008616  0.022867    0.03082396]\n",
      "  [-0.0442851   0.0098606   0.02468357 -0.02099853 -0.03649157\n",
      "    0.04909602  0.04510445  0.03730213 -0.04349843  0.0327948 ]\n",
      "  [-0.00556684  0.02556572 -0.0135365  -0.01451286  0.03697691\n",
      "    0.0062049   0.04696387  0.03639454 -0.02742461 -0.04197062]\n",
      "  [ 0.03615865  0.03577119  0.00148784 -0.03431538 -0.04017918\n",
      "    0.00738523  0.03236402  0.01342156  0.0463609  -0.04213531]\n",
      "  [-0.00358247 -0.03866132 -0.01254008  0.00874057 -0.01523728\n",
      "   -0.01658093 -0.00956402  0.02087395 -0.00400641 -0.01018555]\n",
      "  [ 0.04367344 -0.01152263 -0.01191043  0.00765421  0.01160586\n",
      "    0.01118646  0.04117033  0.04875268  0.04585603  0.01512376]]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(embedded_docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e71fac087ff239f97a80677af45088458db37fbf8ef0a2691e8afa292e413fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
