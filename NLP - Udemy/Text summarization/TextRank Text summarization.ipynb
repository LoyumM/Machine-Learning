{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\Notes and Exercises\\Machine-Learning\\dataset\\bbc_text_cls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = df[df.labels == 'business']['text'].sample(random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(x):\n",
    "    return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karachi stocks hit historic high\n",
      "\n",
      "The Karachi Stock Exchange (KSE) has\n",
      "recorded its largest single day gain, surging 3.5% to a new high.\n",
      "\n",
      "The\n",
      "index rose 225.79 points in four hours of furious trading, with many\n",
      "investors optimistic that political stability could bring an economic\n",
      "boom.  The KSE index closed at 6709.93 - an overall gain of nearly 400\n",
      "points in the first two trading days of the week.  Energy and\n",
      "telecommunication stocks performed particularly well, recording an\n",
      "8%-10% rise since Monday morning.\n",
      "\n",
      "In 2002, the KSE was the world's\n",
      "best performing stock market, with the index rising 112%.\n",
      "\n",
      "Pakistani\n",
      "investors are expecting the KSE to repeat, if not improve on, its 2002\n",
      "performance.  Jubilant investors danced on the streets as the market\n",
      "closed for the day on Tuesday, confident that the boom will continue\n",
      "at least until the public holiday on 22 January.  Others, however, who\n",
      "had stayed out fearing an imminent collapse because of prices\n",
      "overheating, continued to warn that the \"bubble may burst any time\".\n",
      "\"That's rubbish,\" KSE chairman Yaseen Lakhani told the BBC News\n",
      "website.  \"Whenever the market reflects Pakistan's true economic\n",
      "reality, it is described as a bubble.\"  Mr Lakhani feels that the\n",
      "market has risen on the basis of solid economic growth and its current\n",
      "level rests on sound foundations.\n",
      "\n",
      "Market analysts are inclined to\n",
      "agree with Mr Lakhani, arguing that there are a number of major\n",
      "factors behind the KSE's performance.  Analysts argue that a steady\n",
      "improvement in Pakistan's credit ratings by international credit\n",
      "rating agencies has finally begun to register in the market.  Standard\n",
      "& Poor's upgraded Pakistan a few weeks ago.  There are indications of\n",
      "yet another upgrade by the end of February.\n",
      "\n",
      "Then, say analysts, there\n",
      "is corporate profitability in the current fiscal year, which has gone\n",
      "up by 27% from last year.  \"Coupled with the 7% GDP growth expected by\n",
      "June this year, I am least surprised at the market's performance,\"\n",
      "says Mr Lakhani.  One leading Karachi broker said the real reasons may\n",
      "be political.  \"If you file a $1.3 trillion case against Saudi money\n",
      "after 9/11, Arab money will not go to the US any more.\"  A lot of Arab\n",
      "money, he says, has already gone to Malaysia and Indonesia.\n",
      "Pakistanis are now hoping that energy and telecoms, two of the\n",
      "strongest sectors in Pakistan, draw some of the Arab money to the KSE.\n",
      "Locally, too, say analysts, recent political developments have worked\n",
      "to the market's advantage.\n",
      "\n",
      "An anti-Musharraf campaign threatened by\n",
      "the MMA, a countrywide alliance of religious parties, has fizzled out.\n",
      "The release of Asif Zardari, former Prime Minister Benazir Bhutto's\n",
      "husband, has eased political tensions between the military-backed\n",
      "government and the opposition Pakistan People's Party.  Most\n",
      "importantly, say analysts, the failure of talks between India and\n",
      "Pakistan on the Baglihar dam in Indian-administered Kashmir has not\n",
      "automatically led to heightened tensions.  This, they say, indicates\n",
      "that neither country is interested in raising the temperature at this\n",
      "stage, irrespective of the state of their disagreements.  The market\n",
      "is abuzz with speculation that substantial investment may now start to\n",
      "flow in from the US, a country seen locally as deeply interested in\n",
      "defusing tensions between the South Asian neighbours.  \"You can call\n",
      "it a peace dividend,\" smiles one broker.  \"Let us see how long one can\n",
      "reap its benefits.\"\n"
     ]
    }
   ],
   "source": [
    "print(wrap(doc.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Karachi Stock Exchange (KSE) has recorded its largest single day gain, surging 3.5% to a new high.\n",
      "\n",
      "The index rose 225.79 points in four hours of furious trading, with many investors optimistic that political stability could bring an economic boom. The KSE index closed at 6709.93 - an overall gain of nearly 400 points in the first two trading days of the week. Energy and telecommunication stocks performed particularly well, recording an 8%-10% rise since Monday morning.\n",
      "\n",
      "In 2002, the KSE was the world's best performing stock market, with the index rising 112%.\n",
      "\n",
      "Pakistani investors are expecting the KSE to repeat, if not improve on, its 2002 performance. Jubilant investors danced on the streets as the market closed for the day on Tuesday, confident that the boom will continue at least until the public holiday on 22 January. Others, however, who had stayed out fearing an imminent collapse because of prices overheating, continued to warn that the \"bubble may burst any time\". \"That's rubbish,\" KSE chairman Yaseen Lakhani told the BBC News website. \"Whenever the market reflects Pakistan's true economic reality, it is described as a bubble.\" Mr Lakhani feels that the market has risen on the basis of solid economic growth and its current level rests on sound foundations.\n",
      "\n",
      "Market analysts are inclined to agree with Mr Lakhani, arguing that there are a number of major factors behind the KSE's performance. Analysts argue that a steady improvement in Pakistan's credit ratings by international credit rating agencies has finally begun to register in the market. Standard & Poor's upgraded Pakistan a few weeks ago. There are indications of yet another upgrade by the end of February.\n",
      "\n",
      "Then, say analysts, there is corporate profitability in the current fiscal year, which has gone up by 27% from last year. \"Coupled with the 7% GDP growth expected by June this year, I am least surprised at the market's performance,\" says Mr Lakhani. One leading Karachi broker said the real reasons may be political. \"If you file a $1.3 trillion case against Saudi money after 9/11, Arab money will not go to the US any more.\" A lot of Arab money, he says, has already gone to Malaysia and Indonesia. Pakistanis are now hoping that energy and telecoms, two of the strongest sectors in Pakistan, draw some of the Arab money to the KSE.\n",
      "\n",
      "Locally, too, say analysts, recent political developments have worked to the market's advantage.\n",
      "\n",
      "An anti-Musharraf campaign threatened by the MMA, a countrywide alliance of religious parties, has fizzled out. The release of Asif Zardari, former Prime Minister Benazir Bhutto's husband, has eased political tensions between the military-backed government and the opposition Pakistan People's Party. Most importantly, say analysts, the failure of talks between India and Pakistan on the Baglihar dam in Indian-administered Kashmir has not automatically led to heightened tensions. This, they say, indicates that neither country is interested in raising the temperature at this stage, irrespective of the state of their disagreements. The market is abuzz with speculation that substantial investment may now start to flow in from the US, a country seen locally as deeply interested in defusing tensions between the South Asian neighbours. \"You can call it a peace dividend,\" smiles one broker. \"Let us see how long one can reap its benefits.\"\n"
     ]
    }
   ],
   "source": [
    "print(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = nltk.sent_tokenize(doc.iloc[0].split(\"\\n\",1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = TfidfVectorizer(\n",
    "    stop_words = stopwords.words('english'),\n",
    "    norm = 'l1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featurizer.fit_transform(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute cosine similarity\n",
    "S = cosine_similarity(X)\n",
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize similarity matrix\n",
    "S /= S.sum(axis = 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniform transition matrix\n",
    "U = np.ones_like(S) / len(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothed similarity matrix\n",
    "factor = 0.15\n",
    "S = (1-factor) * S + factor * U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the limiting / stationary distribution\n",
    "eigenvals, eigenvecs = np.linalg.eig(S.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.29288592, 0.79674115, 0.77334548, 0.73421504,\n",
       "       0.72570055, 0.70664256, 0.69688054, 0.64291039, 0.33510499,\n",
       "       0.34284901, 0.36394732, 0.6178493 , 0.38247313, 0.39419023,\n",
       "       0.3992621 , 0.42273888, 0.44771178, 0.59102348, 0.58050112,\n",
       "       0.5563091 , 0.47141411, 0.48480058, 0.53159703, 0.50659103,\n",
       "       0.50272007, 0.52332544, 0.85      , 0.85      ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17638882, 0.18244345, 0.18276364, 0.16647279, 0.20056689,\n",
       "       0.18498961, 0.17627064, 0.16195718, 0.16678443, 0.19651731,\n",
       "       0.19018671, 0.2206736 , 0.1773583 , 0.1634555 , 0.18495442,\n",
       "       0.1836724 , 0.2148786 , 0.20217924, 0.18181727, 0.17954981,\n",
       "       0.21938245, 0.21276207, 0.18495442, 0.1693887 , 0.18308151,\n",
       "       0.1627039 , 0.19488777, 0.17113507, 0.1715018 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17638882, 0.18244345, 0.18276364, 0.16647279, 0.20056689,\n",
       "       0.18498961, 0.17627064, 0.16195718, 0.16678443, 0.19651731,\n",
       "       0.19018671, 0.2206736 , 0.1773583 , 0.1634555 , 0.18495442,\n",
       "       0.1836724 , 0.2148786 , 0.20217924, 0.18181727, 0.17954981,\n",
       "       0.21938245, 0.21276207, 0.18495442, 0.1693887 , 0.18308151,\n",
       "       0.1627039 , 0.19488777, 0.17113507, 0.1715018 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0].dot(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03288579, 0.03401461, 0.03407431, 0.03103706, 0.03739353,\n",
       "       0.03448932, 0.03286376, 0.03019517, 0.03109516, 0.03663853,\n",
       "       0.03545826, 0.04114221, 0.03306654, 0.03047452, 0.03448276,\n",
       "       0.03424374, 0.0400618 , 0.03769414, 0.03389787, 0.03347513,\n",
       "       0.04090149, 0.03966719, 0.03448276, 0.0315807 , 0.03413357,\n",
       "       0.03033439, 0.03633472, 0.03190629, 0.03197466])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvecs[:,0] / eigenvecs[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "limiting_dist = np.ones(len(S)) / len(S)\n",
    "threshold = 1e-8\n",
    "delta = float('inf')\n",
    "iters = 0\n",
    "while delta > threshold:\n",
    "  iters += 1\n",
    "\n",
    "  # Markov transition\n",
    "  p = limiting_dist.dot(S)\n",
    "\n",
    "  # compute change in limiting distribution\n",
    "  delta = np.abs(p - limiting_dist).sum()\n",
    "\n",
    "  # update limiting distribution\n",
    "  limiting_dist = p\n",
    "\n",
    "print(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03288579, 0.03401461, 0.03407431, 0.03103707, 0.03739353,\n",
       "       0.03448932, 0.03286376, 0.03019517, 0.03109516, 0.03663853,\n",
       "       0.03545826, 0.04114221, 0.03306654, 0.03047452, 0.03448276,\n",
       "       0.03424374, 0.0400618 , 0.03769414, 0.03389787, 0.03347513,\n",
       "       0.04090149, 0.03966719, 0.03448276, 0.0315807 , 0.03413357,\n",
       "       0.03033439, 0.03633472, 0.03190629, 0.03197466])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999957"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limiting_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3809605580470414e-08"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(eigenvecs[:,0] / eigenvecs[:,0].sum() - limiting_dist).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = limiting_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary:\n",
      "0.04: Market analysts are inclined to agree with Mr Lakhani, arguing\n",
      "that there are a number of major factors behind the KSE's performance.\n",
      "0.04: Pakistanis are now hoping that energy and telecoms, two of the\n",
      "strongest sectors in Pakistan, draw some of the Arab money to the KSE.\n",
      "0.04: \"Coupled with the 7% GDP growth expected by June this year, I am\n",
      "least surprised at the market's performance,\" says Mr Lakhani.\n",
      "0.04: Locally, too, say analysts, recent political developments have\n",
      "worked to the market's advantage.\n",
      "0.04: One leading Karachi broker said the real reasons may be\n",
      "political.\n"
     ]
    }
   ],
   "source": [
    "# Many options for how to choose which sentences to include:\n",
    "\n",
    "# 1) top N sentences\n",
    "# 2) top N words\n",
    "# 3) top X% sentences or top X% words\n",
    "# 4) sentences with scores > average score\n",
    "# 5) sentences with scores > factor * average score\n",
    "\n",
    "# You also don't have to sort. May make more sense in order.\n",
    "\n",
    "print(\"Generated summary:\")\n",
    "for i in sort_idx[:5]:\n",
    "  print(wrap(\"%.2f: %s\" % (scores[i], sents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Karachi stocks hit historic high'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text, factor = 0.15):\n",
    "      # extract sentences\n",
    "  sents = nltk.sent_tokenize(text)\n",
    "\n",
    "  # perform tf-idf\n",
    "  featurizer = TfidfVectorizer(\n",
    "      stop_words=stopwords.words('english'),\n",
    "      norm='l1')\n",
    "  X = featurizer.fit_transform(sents)\n",
    "\n",
    "  # compute similarity matrix\n",
    "  S = cosine_similarity(X)\n",
    "\n",
    "  # normalize similarity matrix\n",
    "  S /= S.sum(axis=1, keepdims=True)\n",
    "\n",
    "  # uniform transition matrix\n",
    "  U = np.ones_like(S) / len(S)\n",
    "\n",
    "  # smoothed similarity matrix\n",
    "  S = (1 - factor) * S + factor * U\n",
    "\n",
    "  # find the limiting / stationary distribution\n",
    "  eigenvals, eigenvecs = np.linalg.eig(S.T)\n",
    "\n",
    "  # compute scores\n",
    "  scores = eigenvecs[:,0] / eigenvecs[:,0].sum()\n",
    "  \n",
    "  # sort the scores\n",
    "  sort_idx = np.argsort(-scores)\n",
    "\n",
    "  # print summary\n",
    "  for i in sort_idx[:5]:\n",
    "    print(wrap(\"%.2f: %s\" % (scores[i], sents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11: Goodrem, Green Day and the Black Eyed Peas took home two awards\n",
      "each.\n",
      "0.10: As well as best female, Goodrem also took home the Pepsi Viewers\n",
      "Choice Award, whilst Green Day bagged the prize for best rock video\n",
      "for American Idiot.\n",
      "0.10: Other winners included Green Day, voted best group, and the\n",
      "Black Eyed Peas.\n",
      "0.10: The Black Eyed Peas won awards for best R 'n' B video and\n",
      "sexiest video, both for Hey Mama.\n",
      "0.10: Local singer and songwriter Missy Higgins took the title of\n",
      "breakthrough artist of the year, with Australian Idol winner Guy\n",
      "Sebastian taking the honours for best pop video.\n"
     ]
    }
   ],
   "source": [
    "doc = df[df.labels == 'entertainment']['text'].sample(random_state=123)\n",
    "summarize(doc.iloc[0].split(\"\\n\", 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goodrem wins top female MTV prize'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.iloc[0].split(\"\\n\")[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries for Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = TextRankSummarizer()\n",
    "parser = PlaintextParser.from_string(\n",
    "    doc.iloc[0].split(\"\\n\", 1)[1],\n",
    "    Tokenizer(\"english\"))\n",
    "summary = summarizer(parser.document, sentences_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Sentence: The 21-year-old singer won the award for best female artist, with Australian Idol runner-up Shannon Noll taking the title of best male at the ceremony.>,\n",
       " <Sentence: As well as best female, Goodrem also took home the Pepsi Viewers Choice Award, whilst Green Day bagged the prize for best rock video for American Idiot.>,\n",
       " <Sentence: The Black Eyed Peas won awards for best R 'n' B video and sexiest video, both for Hey Mama.>,\n",
       " <Sentence: Local singer and songwriter Missy Higgins took the title of breakthrough artist of the year, with Australian Idol winner Guy Sebastian taking the honours for best pop video.>,\n",
       " <Sentence: The ceremony was held at the Luna Park fairground in Sydney Harbour and was hosted by the Osbourne family.>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 21-year-old singer won the award for best female artist, with\n",
      "Australian Idol runner-up Shannon Noll taking the title of best male\n",
      "at the ceremony.\n",
      "As well as best female, Goodrem also took home the Pepsi Viewers\n",
      "Choice Award, whilst Green Day bagged the prize for best rock video\n",
      "for American Idiot.\n",
      "The Black Eyed Peas won awards for best R 'n' B video and sexiest\n",
      "video, both for Hey Mama.\n",
      "Local singer and songwriter Missy Higgins took the title of\n",
      "breakthrough artist of the year, with Australian Idol winner Guy\n",
      "Sebastian taking the honours for best pop video.\n",
      "The ceremony was held at the Luna Park fairground in Sydney Harbour\n",
      "and was hosted by the Osbourne family.\n"
     ]
    }
   ],
   "source": [
    "for s in summary:\n",
    "  print(wrap(str(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodrem, known in both Britain and Australia for her role as Nina\n",
      "Tucker in TV soap Neighbours, also performed a duet with boyfriend\n",
      "Brian McFadden.\n",
      "Other winners included Green Day, voted best group, and the Black Eyed\n",
      "Peas.\n",
      "Goodrem, Green Day and the Black Eyed Peas took home two awards each.\n",
      "As well as best female, Goodrem also took home the Pepsi Viewers\n",
      "Choice Award, whilst Green Day bagged the prize for best rock video\n",
      "for American Idiot.\n",
      "Artists including Carmen Electra, Missy Higgins, Kelly Osbourne, Green\n",
      "Day, Ja Rule and Natalie Imbruglia gave live performances at the\n",
      "event.\n"
     ]
    }
   ],
   "source": [
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, sentences_count=5)\n",
    "for s in summary:\n",
    "  print(wrap(str(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'summarizer' from 'gensim.summarization.summarizer' (c:\\Users\\Loyumba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\summarization\\summarizer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Notes and Exercises\\Machine-Learning\\NLP - Udemy\\Text summarization\\TextRank Text summarization.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarizer\u001b[39;00m \u001b[39mimport\u001b[39;00m summarizer\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'summarizer' from 'gensim.summarization.summarizer' (c:\\Users\\Loyumba\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\summarization\\summarizer.py)"
     ]
    }
   ],
   "source": [
    "from gensim.summarization.summarizer import summarizer\n",
    "# from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Notes and Exercises\\Machine-Learning\\NLP - Udemy\\Text summarization\\TextRank Text summarization.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# https://radimrehurek.com/gensim_3.8.3/summarization/summariser.html\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# https://arxiv.org/abs/1602.03606\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# split (bool, optional) – If True, list of sentences will be returned.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#     Otherwise joined strings will bwe returned.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msummarizer\u001b[39;00m \u001b[39mimport\u001b[39;00m summarize\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m summary \u001b[39m=\u001b[39m summarize(doc\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Notes%20and%20Exercises/Machine-Learning/NLP%20-%20Udemy/Text%20summarization/TextRank%20Text%20summarization.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(wrap(summary))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": [
    "# https://radimrehurek.com/gensim_3.8.3/summarization/summariser.html\n",
    "# https://arxiv.org/abs/1602.03606\n",
    "# Parameters\n",
    "# text (str) – Given text.\n",
    "# ratio (float, optional) – Number between 0 and 1 that determines the\n",
    "#     proportion of the number of sentences of the original text to be\n",
    "#     chosen for the summary.\n",
    "# word_count (int or None, optional) – Determines how many words will the\n",
    "#     output contain. If both parameters are provided, the ratio will be\n",
    "#     ignored.\n",
    "# split (bool, optional) – If True, list of sentences will be returned.\n",
    "#     Otherwise joined strings will bwe returned.\n",
    "from gensim.summarization.summarizer import summarize\n",
    "summary = summarize(doc.iloc[0].split(\"\\n\", 1)[1])\n",
    "print(wrap(summary))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summarization code was removed from Gensim 4.0. See:https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4#12-removed-gensimsummarization\n",
    "\n",
    "If you need it, you could try:\n",
    "\n",
    "- installing an older gensim version (such as 3.8.3, the last official release in which it remained); or…\n",
    "- copy the source code out to your own local module\n",
    "\n",
    "This can be done by creating an env and then installing gensim=3.8.3\n",
    "\n",
    "pip install gensim=3.8.3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
